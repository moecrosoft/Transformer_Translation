{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBGG4D9-NxlK",
        "outputId": "6f076f69-c4e6-4b9c-a439-3cf3aa695615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Ignored the following yanked versions: 0.3.0a0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchdata==0.5.1 (from versions: 0.3.0a1, 0.3.0, 0.6.0, 0.6.1, 0.7.0, 0.7.1, 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchdata==0.5.1\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: spacy==3.7.2 in /usr/local/lib/python3.12/dist-packages (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (3.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy==3.7.2) (1.26.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.2) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.2) (2025.11.12)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.12/dist-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.2) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.3.0,>=8.1.8->spacy==3.7.2) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.12/dist-packages (from typer<0.10.0,>=0.3.0->spacy==3.7.2) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.4.0,>=0.1.0->spacy==3.7.2) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy==3.7.2) (3.0.3)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.12/dist-packages (2.5.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2.7.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2025.11.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (6.0.2)\n",
            "Collecting https://github.com/explosion/spacy-models/releases/download/-de/-de.tar.gz\n",
            "\u001b[31m  ERROR: HTTP error 404 while getting https://github.com/explosion/spacy-models/releases/download/-de/-de.tar.gz\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not install requirement https://github.com/explosion/spacy-models/releases/download/-de/-de.tar.gz because of HTTP error 404 Client Error: Not Found for url: https://github.com/explosion/spacy-models/releases/download/-de/-de.tar.gz for URL https://github.com/explosion/spacy-models/releases/download/-de/-de.tar.gz\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting https://github.com/explosion/spacy-models/releases/download/-en/-en.tar.gz\n",
            "\u001b[31m  ERROR: HTTP error 404 while getting https://github.com/explosion/spacy-models/releases/download/-en/-en.tar.gz\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not install requirement https://github.com/explosion/spacy-models/releases/download/-en/-en.tar.gz because of HTTP error 404 Client Error: Not Found for url: https://github.com/explosion/spacy-models/releases/download/-en/-en.tar.gz for URL https://github.com/explosion/spacy-models/releases/download/-en/-en.tar.gz\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pdfplumber==0.9.0 in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: pdfminer.six==20221105 in /usr/local/lib/python3.12/dist-packages (from pdfplumber==0.9.0) (20221105)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber==0.9.0) (11.3.0)\n",
            "Requirement already satisfied: Wand>=0.6.10 in /usr/local/lib/python3.12/dist-packages (from pdfplumber==0.9.0) (0.6.13)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20221105->pdfplumber==0.9.0) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20221105->pdfplumber==0.9.0) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber==0.9.0) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber==0.9.0) (2.23)\n",
            "Requirement already satisfied: fpdf==1.7.2 in /usr/local/lib/python3.12/dist-packages (1.7.2)\n",
            "--2025-12-18 11:36:50--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/Multi30K_de_en_dataloader.py\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4890 (4.8K) [application/x-python]\n",
            "Saving to: ‘Multi30K_de_en_dataloader.py.1’\n",
            "\n",
            "Multi30K_de_en_data 100%[===================>]   4.78K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-18 11:36:50 (1.59 GB/s) - ‘Multi30K_de_en_dataloader.py.1’ saved [4890/4890]\n",
            "\n",
            "--2025-12-18 11:36:50--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/transformer.pt\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 144559760 (138M) [binary/octet-stream]\n",
            "Saving to: ‘transformer.pt.1’\n",
            "\n",
            "transformer.pt.1    100%[===================>] 137.86M  22.8MB/s    in 6.6s    \n",
            "\n",
            "2025-12-18 11:36:58 (20.8 MB/s) - ‘transformer.pt.1’ saved [144559760/144559760]\n",
            "\n",
            "--2025-12-18 11:36:58--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/input_de.pdf\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.45.118.108\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.45.118.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27628 (27K) [application/pdf]\n",
            "Saving to: ‘input_de.pdf.1’\n",
            "\n",
            "input_de.pdf.1      100%[===================>]  26.98K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-12-18 11:36:59 (323 KB/s) - ‘input_de.pdf.1’ saved [27628/27628]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install -U torchdata==0.5.1\n",
        "!pip install -U spacy==3.7.2\n",
        "!pip install -Uqq portalocker==2.7.0\n",
        "!pip install sacrebleu\n",
        "\n",
        "!python -m spacy download de\n",
        "!python -m spacy download en\n",
        "\n",
        "!pip install pdfplumber==0.9.0\n",
        "!pip install fpdf==1.7.2\n",
        "\n",
        "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/Multi30K_de_en_dataloader.py'\n",
        "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/transformer.pt'\n",
        "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/input_de.pdf'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.16.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2U9tMhMVuGp",
        "outputId": "42d564e0-dc1a-452e-9442-d0927e452c2e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.16.2\n",
            "  Using cached torchtext-0.16.2-cp312-cp312-manylinux1_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.16.2) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.16.2) (2.32.4)\n",
            "Collecting torch==2.2.0 (from torchtext==0.16.2)\n",
            "  Using cached torch-2.2.0-cp312-cp312-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext==0.16.2) (1.26.4)\n",
            "Collecting torchdata==0.7.1 (from torchtext==0.16.2)\n",
            "  Using cached torchdata-0.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0->torchtext==0.16.2) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0->torchtext==0.16.2) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0->torchtext==0.16.2) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0->torchtext==0.16.2) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0->torchtext==0.16.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0->torchtext==0.16.2) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0->torchtext==0.16.2)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0->torchtext==0.16.2)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0->torchtext==0.16.2)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0->torchtext==0.16.2)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0->torchtext==0.16.2)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0->torchtext==0.16.2)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0->torchtext==0.16.2)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0->torchtext==0.16.2)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0->torchtext==0.16.2)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0->torchtext==0.16.2)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0->torchtext==0.16.2)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.0->torchtext==0.16.2)\n",
            "  Downloading triton-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.12/dist-packages (from torchdata==0.7.1->torchtext==0.16.2) (2.5.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->torchtext==0.16.2) (12.6.85)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.16.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.16.2) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.16.2) (2025.11.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.2.0->torchtext==0.16.2) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.0->torchtext==0.16.2) (1.3.0)\n",
            "Downloading torchtext-0.16.2-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.0-cp312-cp312-manylinux1_x86_64.whl (755.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.4/755.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.7.1-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.4/184.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchdata, torchtext\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu126\n",
            "    Uninstalling torch-2.9.0+cu126:\n",
            "      Successfully uninstalled torch-2.9.0+cu126\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.11.0\n",
            "    Uninstalling torchdata-0.11.0:\n",
            "      Successfully uninstalled torchdata-0.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.7.1 which is incompatible.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 torchdata-0.7.1 torchtext-0.16.2 triton-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the necessary libraries\n",
        "\n",
        "from torchtext.datasets import multi30k,Multi30k\n",
        "import torch\n",
        "from typing import Iterable,List\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "def warn(*args,**kwargs):\n",
        "  pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "gmCT-uibRarH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign unique indexes\n",
        "\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>','<pad>','<bos>','<eos>']"
      ],
      "metadata": {
        "id": "h8YtSw_lS-Ry"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# German model\n",
        "!pip install https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl\n",
        "\n",
        "# English model\n",
        "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.0/en_core_web_sm-3.7.0-py3-none-any.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptJoG9BpekWL",
        "outputId": "b1d43739-e5cc-4f04-e603-1aeb113c21a5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from de-core-news-sm==3.7.0) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2025.11.12)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.12/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.12/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.3)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "Collecting en-core-web-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.0/en_core_web_sm-3.7.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from en-core-web-sm==3.7.0) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2025.11.12)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.12/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.12/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.3)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en_core_web_sm 3.8.0\n",
            "    Uninstalling en_core_web_sm-3.8.0:\n",
            "      Successfully uninstalled en_core_web_sm-3.8.0\n",
            "Successfully installed en-core-web-sm-3.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the pre written python script\n",
        "\n",
        "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/Multi30K_de_en_dataloader.py'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwMfb4hmYkvi",
        "outputId": "d740380a-6e19-469a-a442-a89c373b9215"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-18 11:40:51--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/Multi30K_de_en_dataloader.py\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4890 (4.8K) [application/x-python]\n",
            "Saving to: ‘Multi30K_de_en_dataloader.py.2’\n",
            "\n",
            "Multi30K_de_en_data 100%[===================>]   4.78K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-18 11:40:52 (968 MB/s) - ‘Multi30K_de_en_dataloader.py.2’ saved [4890/4890]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the pre written python scipt so all the functions and variables inside becomes available\n",
        "\n",
        "%run Multi30K_de_en_dataloader.py"
      ],
      "metadata": {
        "id": "QQp1yUeHTn_M"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get train_dataloader and make it an iterable\n",
        "\n",
        "train_dataloader, _ = get_translation_dataloaders(batch_size = 1)\n",
        "\n",
        "data_itr = iter(train_dataloader)\n",
        "data_itr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUvYa5gxUxz4",
        "outputId": "15f68caf-7846-45a7-fb41-0e0c532617fc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader._SingleProcessDataLoaderIter at 0x7ab6ab7469f0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Skip the first 1000 pairs\n",
        "\n",
        "for n in range(1000):\n",
        "  german, english = next(data_itr)"
      ],
      "metadata": {
        "id": "Ag3XoEHLVffT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "german = german.T\n",
        "english = english.T"
      ],
      "metadata": {
        "id": "lc1yiX-GVx8O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the source german and target english sentences\n",
        "\n",
        "for n in range(10):\n",
        "  german,english = next(data_itr)\n",
        "\n",
        "  print('sample {}'.format(n+1))\n",
        "  print('german input')\n",
        "  print(index_to_german(german))\n",
        "  print('english target')\n",
        "  print(index_to_eng(english))\n",
        "  print(\"_________\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYU_reu5V_Yk",
        "outputId": "afee15f0-ee18-4b3d-a5d7-9ab6247dcbcd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample 1\n",
            "german input\n",
            "<bos> Ein Feuerwehrangehöriger arbeitet bei einem Brand . <eos>\n",
            "english target\n",
            "<bos> A firefighter is working at a fire . <eos>\n",
            "_________\n",
            "\n",
            "sample 2\n",
            "german input\n",
            "<bos> Ein Mann spielt auf einem Flügel . <eos>\n",
            "english target\n",
            "<bos> A man playing a black grand piano . <eos>\n",
            "_________\n",
            "\n",
            "sample 3\n",
            "german input\n",
            "<bos> Ein brauner Hund spielt im Schnee . <eos>\n",
            "english target\n",
            "<bos> A brown dog plays in the snow . <eos>\n",
            "_________\n",
            "\n",
            "sample 4\n",
            "german input\n",
            "<bos> Mehrere Hunde in einem winterlichen Ambiente . <eos>\n",
            "english target\n",
            "<bos> Several dogs grouped together in a winter setting . <eos>\n",
            "_________\n",
            "\n",
            "sample 5\n",
            "german input\n",
            "<bos> Ein Mann klettert einen Felsen hoch . <eos>\n",
            "english target\n",
            "<bos> A man climbs up a rock . <eos>\n",
            "_________\n",
            "\n",
            "sample 6\n",
            "german input\n",
            "<bos> Zwei Teams kämpfen um den Sieg . <eos>\n",
            "english target\n",
            "<bos> Two teams battle it out for the win ! <eos>\n",
            "_________\n",
            "\n",
            "sample 7\n",
            "german input\n",
            "<bos> Kinder spielen in einem aufblasbaren Spielplatz . <eos>\n",
            "english target\n",
            "<bos> Kids play in a blow up playground . <eos>\n",
            "_________\n",
            "\n",
            "sample 8\n",
            "german input\n",
            "<bos> Ein kleiner Junge malt einen Teller . <eos>\n",
            "english target\n",
            "<bos> A little boy is paining a plate . <eos>\n",
            "_________\n",
            "\n",
            "sample 9\n",
            "german input\n",
            "<bos> Die beiden Frauen blicken auf etwas . <eos>\n",
            "english target\n",
            "<bos> The two woman are looking at something . <eos>\n",
            "_________\n",
            "\n",
            "sample 10\n",
            "german input\n",
            "<bos> Fünf Kricketspieler liegen auf dem Gras . <eos>\n",
            "english target\n",
            "<bos> Five cricket players are lounging on the grass . <eos>\n",
            "_________\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set to CPU or GPU according to device\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awdI42aGXWWr",
        "outputId": "77c1292c-a9e5-433a-dae7-8fe948ad5899"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate casual masks for the decoder so it only looks at the previous tokens not the future tokens\n",
        "\n",
        "def generate_square_subsequent_mask(sz,device=DEVICE):\n",
        " mask = (torch.triu(torch.ones((sz,sz),device=device)) == 1).transpose(0,1)\n",
        " mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        " return mask"
      ],
      "metadata": {
        "id": "S0jyEASaXjM6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create casual masks, source masks and padding masks\n",
        "\n",
        "def create_mask(src,tgt,device=DEVICE):\n",
        "  src_seq_len = src.shape[0]\n",
        "  tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "  tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "  src_mask = torch.zeros((src_seq_len,src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "  src_padding_mask = (src == PAD_IDX).transpose(0,1)\n",
        "  tgt_padding_mask = (tgt == PAD_IDX).transpose(0,1)\n",
        "  return src_mask,tgt_mask,src_padding_mask,tgt_padding_mask"
      ],
      "metadata": {
        "id": "Cohi-QrSbsiO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Positional Encoding class\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self,emb_size: int,dropout: float,maxlen: int = 5000):\n",
        "    super().__init__()\n",
        "    den = torch.exp(- torch.arange(0,emb_size,2)*math.log(10000) / emb_size)\n",
        "    pos = torch.arange(0,maxlen).reshape(maxlen,1)\n",
        "    pos_embedding = torch.zeros((maxlen,emb_size))\n",
        "    pos_embedding[:,0::2] = torch.sin(pos * den)\n",
        "    pos_embedding[:,1::2] = torch.cos(pos * den)\n",
        "    pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer('pos_embedding',pos_embedding)\n",
        "\n",
        "  def forward(self,token_embedding: Tensor):\n",
        "    return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0),:])"
      ],
      "metadata": {
        "id": "3h82Dm8EinMy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TokenEmbedding class\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "  def __init__(self,vocab_size: int,emb_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size,emb_size)\n",
        "    self.emb_size = emb_size\n",
        "\n",
        "  def forward(self,tokens: Tensor):\n",
        "    return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
      ],
      "metadata": {
        "id": "UkH9q7BdlsQ5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full Seq2Seq Transformer, with PostionalEncoding, TokenEmbedding, encoders and decoders\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "  def __init__(self,\n",
        "               num_encoder_layers: int,\n",
        "               num_decoder_layers: int,\n",
        "               emb_size: int,\n",
        "               nhead: int,\n",
        "               src_vocab_size: int,\n",
        "               tgt_vocab_size: int,\n",
        "               dim_feedforward: int=512,\n",
        "               dropout: float=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.src_token_emb = TokenEmbedding(src_vocab_size,emb_size)\n",
        "    self.tgt_token_emb = TokenEmbedding(tgt_vocab_size,emb_size)\n",
        "    self.positional_encoding = PositionalEncoding(emb_size,dropout=dropout)\n",
        "    self.transformer = Transformer(d_model=emb_size,\n",
        "                                   nhead=nhead,\n",
        "                                   num_encoder_layers=num_encoder_layers,\n",
        "                                   num_decoder_layers=num_decoder_layers,\n",
        "                                   dim_feedforward=dim_feedforward,\n",
        "                                   dropout=dropout)\n",
        "    self.generator = nn.Linear(emb_size,tgt_vocab_size)\n",
        "\n",
        "  def forward(self,\n",
        "              src: Tensor,\n",
        "              trg: Tensor,\n",
        "              src_mask: Tensor,\n",
        "              tgt_mask: Tensor,\n",
        "              src_padding_mask: Tensor,\n",
        "              tgt_padding_mask: Tensor,\n",
        "              memory_key_padding_mask: Tensor):\n",
        "    src_emb = self.positional_encoding(self.src_token_emb(src))\n",
        "    tgt_emb = self.positional_encoding(self.tgt_token_emb(trg))\n",
        "    outs = self.transformer(src_emb,tgt_emb,src_mask,tgt_mask,None,\n",
        "                            src_padding_mask,tgt_padding_mask,memory_key_padding_mask)\n",
        "    outs = outs.to(DEVICE)\n",
        "    return self.generator(outs)\n",
        "\n",
        "  def encode(self,src: Tensor,src_mask: Tensor):\n",
        "    return self.transformer.encoder(self.positional_encoding(\n",
        "        self.src_token_emb(src)),src_mask)\n",
        "\n",
        "  def decode(self,tgt: Tensor,memory: Tensor,tgt_mask: Tensor):\n",
        "    return self.transformer.decoder(self.positional_encoding(\n",
        "        self.tgt_token_emb(tgt)),memory,tgt_mask)\n"
      ],
      "metadata": {
        "id": "BNtBCzIVm48b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate the transformer and use xavier to initialize the layer weights\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "SRC_LANGUAGE = 'de'\n",
        "TGT_LANGUAGE = 'en'\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "EMB_SIZE = 512\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 128\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS,NUM_DECODER_LAYERS,EMB_SIZE,\n",
        "                                 NHEAD,SRC_VOCAB_SIZE,TGT_VOCAB_SIZE,FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "  if p.dim() > 1:\n",
        "    nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(DEVICE)"
      ],
      "metadata": {
        "id": "1UCFwme11V3f"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 100 source and target\n",
        "\n",
        "for n in range(100):\n",
        "  src,tgt = next(data_itr)"
      ],
      "metadata": {
        "id": "t5A5BTCx3_oj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the source and target tokens into actual sentences\n",
        "\n",
        "print('english target',index_to_eng(tgt))\n",
        "print('german input',index_to_german(src))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVuUmMRb4Yok",
        "outputId": "428a82d6-a940-4883-f27d-bec86f4980cb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "english target <bos> A worker taking a reading on a subway train . <eos>\n",
            "german input <bos> Ein Arbeiter liest in einem U-Bahn-Zug . <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of tokens\n",
        "\n",
        "num_tokens = src.shape[0]\n",
        "num_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB476PV14o0T",
        "outputId": "13802055-c821-4dd8-d967-796fb25f4c65"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create source masks\n",
        "\n",
        "src_mask = (torch.zeros(num_tokens,num_tokens)).type(torch.bool).to(DEVICE)\n",
        "src_mask[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U1OxzCO423x",
        "outputId": "e2dd91ae-fc39-4f4e-b841-ef6223ac59e7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False, False, False, False]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src = src[:,0].unsqueeze(1)\n",
        "print(src.shape)\n",
        "print(src.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y1wExKU5g4o",
        "outputId": "f88316e4-54f1-435d-a208-5ad9e41f9634"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9, 1])\n",
            "torch.Size([9, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass the source sentence into the encoder and get memory as output\n",
        "\n",
        "memory = transformer.encode(src,src_mask)\n",
        "memory.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar8l4X2x6-1_",
        "outputId": "793ffa6a-5f5d-4350-e150-83fd62f2f404"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9, 1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a first token of <bos> as input for the decoder\n",
        "\n",
        "ys = torch.ones(1,1).fill_(BOS_IDX).type(torch.long).to(DEVICE)\n",
        "ys"
      ],
      "metadata": {
        "id": "y4PzBeKD7GGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ae3718d-5a8c-495d-968c-520cb2dcd3c3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create target token masks for the decoder\n",
        "\n",
        "tgt_mask = (generate_square_subsequent_mask(ys.size(0)).type(torch.bool)).to(DEVICE)\n",
        "tgt_mask"
      ],
      "metadata": {
        "id": "RJ5vg3p47enJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1077bc78-d0c6-43ee-a3f2-62c008a633d2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get decoder outputs\n",
        "\n",
        "out = transformer.decode(ys,memory,tgt_mask)\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIW1Xigx71Cg",
        "outputId": "f817ca36-17ce-4c83-f6e2-1b2d2e9ba321"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose the decoder outputs, swap the seq length and batch size\n",
        "\n",
        "out = out.transpose(0,1)\n",
        "out.shape"
      ],
      "metadata": {
        "id": "g9wxZbrC8Ezx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46289b75-4bf4-47c3-c3b4-548ddb2249d9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get logits by passing the decoder outputs into transformer generator layer\n",
        "\n",
        "logit = transformer.generator(out[:,-1])\n",
        "logit.shape"
      ],
      "metadata": {
        "id": "83yPKDv18RMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be515343-56a5-4d43-a7c9-2a7f992f0a3e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10837])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted word token index\n",
        "\n",
        "_,next_word_index = torch.max(logit,dim=1)"
      ],
      "metadata": {
        "id": "oAv9T6oI8mhv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the predicted token into a sentence\n",
        "\n",
        "print('english output:',index_to_eng(next_word_index))"
      ],
      "metadata": {
        "id": "rzCuEomX988I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a4817ea-d627-47d7-cca7-07cc84299e46"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "english output: ornaments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the predicted token index\n",
        "\n",
        "next_word_index=next_word_index.item()\n",
        "next_word_index"
      ],
      "metadata": {
        "id": "ziaFMXbV-YqT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "592137a4-3a96-4a06-89e7-2f486e513c5e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9484"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Append the predicted token to the other predicted tokens\n",
        "\n",
        "ys = torch.cat([ys,torch.ones(1,1).type_as(src.data).fill_(next_word_index)],dim=0)\n",
        "ys"
      ],
      "metadata": {
        "id": "okhohA8A-kUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e13afa8-111f-4934-e578-1a8ae226491e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   2],\n",
              "        [9484]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new target masks according to the new predicted tokens size\n",
        "\n",
        "tgt_mask = (generate_square_subsequent_mask(ys.size(0)).type(torch.bool)).to(DEVICE)\n",
        "tgt_mask"
      ],
      "metadata": {
        "id": "HB9N_lyy_Eb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc449ca-2c8f-46f3-ed69-724cc2633fdc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True],\n",
              "        [False, False]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the outputs from the decoder\n",
        "\n",
        "out = transformer.decode(ys,memory,tgt_mask)\n",
        "out = out.transpose(0,1)\n",
        "out.shape"
      ],
      "metadata": {
        "id": "a5ZsrkUy_jyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af055f71-e48e-417b-cde8-5a9df7985658"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out[:,-1].shape"
      ],
      "metadata": {
        "id": "c69cyNAI_9cl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a563c78f-a25d-4f11-c166-1943dde5766f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get logits, get the highest logit token index, and check its sentence\n",
        "\n",
        "prob = transformer.generator(out[:,-1])\n",
        "_,next_word_index = torch.max(prob,dim=1)\n",
        "print('English output:',index_to_eng(next_word_index))\n",
        "next_word_index = next_word_index.item()"
      ],
      "metadata": {
        "id": "xz7eHVlZAAz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89689c8f-4ad0-4236-d70d-794891471a82"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English output: Tannehill\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Append the token index to predicted tokens\n",
        "\n",
        "ys = torch.cat([ys,torch.ones(1,1).type_as(src.data).fill_(next_word_index)],dim=0)\n",
        "print('english output',index_to_eng(ys))"
      ],
      "metadata": {
        "id": "hzvh8PwIAdoi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "813e418e-0ab0-4b98-94d5-c5d8dcb00e95"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "english output <bos> ornaments Tannehill\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for greedy_decode\n",
        "\n",
        "def greedy_decode(model,src,src_mask,max_len,start_symbol):\n",
        "  src = src.to(DEVICE)\n",
        "  src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "  memory = model.encode(src,src_mask)\n",
        "  ys = torch.ones(1,1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "  for i in range(max_len-1):\n",
        "    memory = memory.to(DEVICE)\n",
        "    tgt_mask = (generate_square_subsequent_mask(ys.size(0)).type(torch.bool)).to(DEVICE)\n",
        "    out = model.decode(ys,memory,tgt_mask)\n",
        "    out = out.transpose(0,1)\n",
        "    prob = model.generator(out[:,-1])\n",
        "    _,next_word = torch.max(prob,dim=1)\n",
        "    next_word = next_word.item()\n",
        "\n",
        "    ys = torch.cat([ys,torch.ones(1,1).type_as(src.data).fill_(next_word)],dim=0)\n",
        "    if next_word == EOS_IDX:\n",
        "      break\n",
        "  return ys"
      ],
      "metadata": {
        "id": "GztSpgjUAwaq"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a source mask\n",
        "\n",
        "src\n",
        "src_mask = (torch.zeros(num_tokens,num_tokens)).type(torch.bool).to(DEVICE)"
      ],
      "metadata": {
        "id": "mIwjWDOTDBC1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Max len for the greedy decoder\n",
        "\n",
        "max_len = src.shape[0]+5\n",
        "max_len"
      ],
      "metadata": {
        "id": "EXP0H7zBDPuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3feef783-a812-4707-a0e3-ec55fccc5a72"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predicted tokens using greedy decoder function\n",
        "\n",
        "ys = greedy_decode(transformer,src,src_mask,max_len,start_symbol=BOS_IDX)\n",
        "print('english',index_to_eng(ys))"
      ],
      "metadata": {
        "id": "J5x86woJDkj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8518e9-23ec-4aa0-be85-17f81c529a7c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "english <bos> dinner courtyard pulleys glossy glossy awkwardly Tannehill vans View Houston vans golfing Human\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the tokens into the english sentence\n",
        "\n",
        "print('english',index_to_eng(tgt))"
      ],
      "metadata": {
        "id": "FpYVkD_TD72U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ee7d1f-098c-4746-8866-47c6a14e4f6d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "english <bos> A worker taking a reading on a subway train . <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create loss function using CrossEntropyLoss\n",
        "\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "loss_fn = CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "metadata": {
        "id": "MhYdgOFWEF0l"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create target input by excluding eos token\n",
        "\n",
        "tgt_input = tgt[:-1,:]\n",
        "print(index_to_eng(tgt_input))\n",
        "print(index_to_eng(tgt))"
      ],
      "metadata": {
        "id": "zlydAVi1FFdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bdfbd8d-7bbc-4fe3-8227-025d08db5645"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bos> A worker taking a reading on a subway train .\n",
            "<bos> A worker taking a reading on a subway train . <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create source mask, casual mask and source/target padding masks\n",
        "\n",
        "src_mask,tgt_mask,src_padding_mask,tgt_padding_mask = create_mask(src,tgt_input)\n",
        "print(f\"Shape of src_mask: {src_mask.shape}\")\n",
        "print(f\"Shape of tgt_mask: {tgt_mask.shape}\")\n",
        "print(f\"Shape of src_padding_mask: {src_padding_mask.shape}\")\n",
        "print(f\"Shape of tgt_padding_mask: {tgt_padding_mask.shape}\")"
      ],
      "metadata": {
        "id": "Qe7FsEeDFaeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "771829e4-56c0-4f95-a526-3e51fc912762"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of src_mask: torch.Size([9, 9])\n",
            "Shape of tgt_mask: torch.Size([11, 11])\n",
            "Shape of src_padding_mask: torch.Size([1, 9])\n",
            "Shape of tgt_padding_mask: torch.Size([1, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the target masks\n",
        "\n",
        "print(tgt_mask)\n",
        "[index_to_eng(tgt_input[t==0]) for t in tgt_mask]"
      ],
      "metadata": {
        "id": "4RR2TpTpFrUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b55a81e-63d6-4d75-a3f1-ec0950100ff1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<bos>',\n",
              " '<bos> A',\n",
              " '<bos> A worker',\n",
              " '<bos> A worker taking',\n",
              " '<bos> A worker taking a',\n",
              " '<bos> A worker taking a reading',\n",
              " '<bos> A worker taking a reading on',\n",
              " '<bos> A worker taking a reading on a',\n",
              " '<bos> A worker taking a reading on a subway',\n",
              " '<bos> A worker taking a reading on a subway train',\n",
              " '<bos> A worker taking a reading on a subway train .']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the logits from transformer\n",
        "\n",
        "logits = transformer(src,tgt_input,src_mask,tgt_mask,src_padding_mask,tgt_padding_mask,src_padding_mask)\n",
        "\n",
        "print(\"output shape\",logits.shape)\n",
        "print(\"target shape\",tgt_input.shape)\n",
        "print(\"source shape \",src.shape)"
      ],
      "metadata": {
        "id": "lroWru2SGMqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "083e62da-27a7-4bc8-ba42-dc3fe5c192ee"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output shape torch.Size([11, 1, 10837])\n",
            "target shape torch.Size([11, 1])\n",
            "source shape  torch.Size([9, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Target columns without bos for evaluation\n",
        "\n",
        "tgt_out = tgt[1:,:]\n",
        "print(tgt_out.shape)\n",
        "[index_to_eng(t) for t in tgt_out]"
      ],
      "metadata": {
        "id": "yluGywuLGyW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040acda3-341f-45a9-ccad-1d765879483b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([11, 1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'worker',\n",
              " 'taking',\n",
              " 'a',\n",
              " 'reading',\n",
              " 'on',\n",
              " 'a',\n",
              " 'subway',\n",
              " 'train',\n",
              " '.',\n",
              " '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the target tokens\n",
        "\n",
        "tgt_out_flattened = tgt_out.reshape(-1)\n",
        "print(tgt_out_flattened.shape)\n",
        "tgt_out_flattened"
      ],
      "metadata": {
        "id": "Hh65HxKaHUmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8905e7f8-d123-4809-d719-cdb8bfec55bf"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([11])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  6, 348, 168,   4, 217,   9,   4, 369, 240,   5,   3],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[\"input: {} target: {}\".format(index_to_eng( tgt_input[m==0]),index_to_eng( t))  for m,t in zip(tgt_mask,tgt_out)]"
      ],
      "metadata": {
        "id": "rS7GosY4HnyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea59dd6-4e6b-45df-9b17-c6e6ff3dfd70"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['input: <bos> target: A',\n",
              " 'input: <bos> A target: worker',\n",
              " 'input: <bos> A worker target: taking',\n",
              " 'input: <bos> A worker taking target: a',\n",
              " 'input: <bos> A worker taking a target: reading',\n",
              " 'input: <bos> A worker taking a reading target: on',\n",
              " 'input: <bos> A worker taking a reading on target: a',\n",
              " 'input: <bos> A worker taking a reading on a target: subway',\n",
              " 'input: <bos> A worker taking a reading on a subway target: train',\n",
              " 'input: <bos> A worker taking a reading on a subway train target: .',\n",
              " 'input: <bos> A worker taking a reading on a subway train . target: <eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the loss using CrossEntropy\n",
        "\n",
        "loss = loss_fn(logits.reshape(-1,logits.shape[-1]),tgt_out.reshape(-1))\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "Bagp8XOdIW62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87fa6a32-1a2e-4432-b71b-e3cd0e7c7e00"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9.4537, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the logits and target output's shapes before and after flattening\n",
        "\n",
        "print(\"logit's shape is:\",logits.shape)\n",
        "logits_flattened = logits.reshape(-1,logits.shape[-1])\n",
        "print(\"logit_flat's shape is:\",logits_flattened.shape)\n",
        "\n",
        "print(\"tgt_out's shape is:\",tgt_out.shape)\n",
        "tgt_out_flattened = tgt_out.reshape(-1)\n",
        "print(\"tgt_out_flat's shape is:\",tgt_out_flattened.shape)"
      ],
      "metadata": {
        "id": "u-yB1e1dIpyq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a545a1f-9413-491b-c1c8-908137ef5af7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logit's shape is: torch.Size([11, 1, 10837])\n",
            "logit_flat's shape is: torch.Size([11, 10837])\n",
            "tgt_out's shape is: torch.Size([11, 1])\n",
            "tgt_out_flat's shape is: torch.Size([11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the probabilites of logits using softmax\n",
        "\n",
        "probs = torch.nn.functional.softmax(logits_flattened,dim=1)\n",
        "probs[1].sum()"
      ],
      "metadata": {
        "id": "FM5xzGYCJWMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05f7690-815f-413a-b310-ded44936b76c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0000, device='cuda:0', grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted and actual token ids. Then check the predicted probabilities\n",
        "\n",
        "for i in range(5):\n",
        "  print(\"Predicted token id:\",probs[i].argmax().item(), \"predicted probability:\",probs[i].max().item())\n",
        "  print(\"Actual token id:\",tgt_out_flattened[i].item(), \"predicted probability:\", probs[i,tgt_out_flattened[i]].item(),\"\\n\")"
      ],
      "metadata": {
        "id": "2jhYE437JkPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ca8a1a-65eb-4b61-e5ea-9fa1842f2744"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted token id: 7637 predicted probability: 0.00027637684252113104\n",
            "Actual token id: 6 predicted probability: 8.007132419152185e-05 \n",
            "\n",
            "Predicted token id: 4772 predicted probability: 0.00031224358826875687\n",
            "Actual token id: 348 predicted probability: 6.282160757109523e-05 \n",
            "\n",
            "Predicted token id: 2355 predicted probability: 0.00027612849953584373\n",
            "Actual token id: 168 predicted probability: 5.2986091759521514e-05 \n",
            "\n",
            "Predicted token id: 3605 predicted probability: 0.0002890959440264851\n",
            "Actual token id: 4 predicted probability: 4.712984446086921e-05 \n",
            "\n",
            "Predicted token id: 8794 predicted probability: 0.00029878492932766676\n",
            "Actual token id: 217 predicted probability: 0.00012535354471765459 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the log loss\n",
        "\n",
        "neg_log_likelihood = torch.nn.functional.nll_loss(probs, tgt_out_flattened)\n",
        "loss = neg_log_likelihood\n",
        "\n",
        "print(\"Loss:\", loss.item())"
      ],
      "metadata": {
        "id": "Swv3B4qGJ5Rq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc666273-f6d4-40ad-a840-54ca50ab62a3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: -8.269331738119945e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for evaluation\n",
        "\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(val_dataloader))"
      ],
      "metadata": {
        "id": "e1i57g87KLhC"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for training\n",
        "\n",
        "def train_epoch(model, optimizer, train_dataloader):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "\n",
        "    train_iterator = tqdm(train_dataloader, desc=\"Training\", leave=False)\n",
        "\n",
        "    for src, tgt in train_iterator:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "        src_mask = src_mask.to(DEVICE)\n",
        "        tgt_mask = tgt_mask.to(DEVICE)\n",
        "        src_padding_mask = src_padding_mask.to(DEVICE)\n",
        "        tgt_padding_mask = tgt_padding_mask.to(DEVICE)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "        logits = logits.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "        train_iterator.set_postfix(loss=loss.item())\n",
        "\n",
        "    return losses / len(list(train_dataloader))"
      ],
      "metadata": {
        "id": "-6rurCUVKN3L"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model configurations\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "EMB_SIZE = 512\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 128\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3"
      ],
      "metadata": {
        "id": "RXZgrdcbKQPv"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and validation dataloaders\n",
        "\n",
        "train_dataloader, val_dataloader = get_translation_dataloaders(batch_size = BATCH_SIZE)"
      ],
      "metadata": {
        "id": "WxohZ1UpKR_K"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate the transformer model\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "transformer = transformer.to(DEVICE)"
      ],
      "metadata": {
        "id": "GEZ5tVDxKTwO"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the optimizer\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ],
      "metadata": {
        "id": "ETok72-YKVYZ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists to store the training and validation loss\n",
        "\n",
        "TrainLoss=[]\n",
        "ValLoss=[]"
      ],
      "metadata": {
        "id": "WlqX7cbZKX5y"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the transformer, checking the loss and saving the model state_dict\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train_epoch(transformer, optimizer, train_dataloader)\n",
        "    TrainLoss.append(train_loss)\n",
        "    end_time = timer()\n",
        "    val_loss = evaluate(transformer)\n",
        "    ValLoss.append(val_loss)\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
        "torch.save(transformer.state_dict(), 'transformer_de_to_en_model.pt')"
      ],
      "metadata": {
        "id": "4WkhWJm3KZzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa5ac8bf-98e3-4180-aed5-853ade89ef83"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train loss: 5.079, Val loss: 4.389, Epoch time = 34.659s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2, Train loss: 3.883, Val loss: 3.818, Epoch time = 35.610s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3, Train loss: 3.488, Val loss: 3.594, Epoch time = 36.028s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4, Train loss: 3.233, Val loss: 3.412, Epoch time = 38.248s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Train loss: 3.039, Val loss: 3.258, Epoch time = 36.791s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6, Train loss: 2.879, Val loss: 3.137, Epoch time = 37.579s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7, Train loss: 2.744, Val loss: 3.038, Epoch time = 37.635s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8, Train loss: 2.625, Val loss: 2.943, Epoch time = 36.866s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9, Train loss: 2.517, Val loss: 2.865, Epoch time = 36.418s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Train loss: 2.424, Val loss: 2.782, Epoch time = 36.379s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the transformer training and validation loss\n",
        "\n",
        "epochs = range(1, len(TrainLoss) + 1)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, TrainLoss, 'r', label='Training loss')\n",
        "plt.plot(epochs,ValLoss, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sZ1Nt3vgKb09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "bc4984ad-f9d6-4991-99e2-43e810f224d3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained state_dict into the transformer\n",
        "\n",
        "transformer.load_state_dict(torch.load('transformer_de_to_en_model.pt',map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "id": "5KD6_xOQKduj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aede77de-dc65-455d-a19a-11c83d5c76f5"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate translations\n",
        "\n",
        "def translate(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ],
      "metadata": {
        "id": "IgmTppGGKgHI"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Translate the german sentence to english\n",
        "\n",
        "for n in range(5):\n",
        "    german, english= next(data_itr)\n",
        "\n",
        "    print(\"German Sentence:\",index_to_german(german).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
        "    print(\"English Translation:\",index_to_eng(english).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
        "    print(\"Model Translation:\",translate(transformer,index_to_german(german)))\n",
        "    print(\"_________\\n\")"
      ],
      "metadata": {
        "id": "Ib7tCg1kKilu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02021714-a90e-4a6a-a3cd-f1b676eff0f0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "German Sentence:  Männer stehen neben irgendeiner hydraulischen Maschine . \n",
            "English Translation:  Men are standing next to some sort of hydraulic machine . \n",
            "Model Translation:  Men stand next to a basketball to some sort of some sort of water . \n",
            "_________\n",
            "\n",
            "German Sentence:  Zwei Arbeiter reinigen nachts ein Bauwerk . \n",
            "English Translation:  Two workers are cleaning a structure at night . \n",
            "Model Translation:  Two workers are a yellow boat at night of a night . \n",
            "_________\n",
            "\n",
            "German Sentence:  Sieben Bauarbeiter arbeiten an einem Gebäude . \n",
            "English Translation:  Seven construction workers working on a building . \n",
            "Model Translation:  Construction workers work on a building work on a building work on a building . \n",
            "_________\n",
            "\n",
            "German Sentence:  Die Kinder spielen nachts mit Wunderkerzen . \n",
            "English Translation:  The children play with sparklers at night . \n",
            "Model Translation:  The children are playing with a green shirt is watching a few children play with a crowd of them\n",
            "_________\n",
            "\n",
            "German Sentence:  Ein älteres Paar geht zusammen spazieren . \n",
            "English Translation:  An older couple taking a walk together . \n",
            "Model Translation:  A couple walk together together together in a couple of water area . \n",
            "_________\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate BLEU score\n",
        "\n",
        "import sacrebleu\n",
        "\n",
        "def calculate_bleu_score(generated_translation, reference_translations):\n",
        "\n",
        "    bleu_score = sacrebleu.corpus_bleu([generated_translation],[reference_translations])\n",
        "\n",
        "    return bleu_score"
      ],
      "metadata": {
        "id": "QNLzGCL0KkJQ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate BLEU score of the model translation\n",
        "\n",
        "generated_translation = translate(transformer,\"Ein brauner Hund spielt im Schnee .\")\n",
        "\n",
        "reference_translations = [\n",
        "    \"A brown dog is playing in the snow .\",\n",
        "    \"A brown dog plays in the snow .\",\n",
        "    \"A brown dog is frolicking in the snow .\",\n",
        "    \"In the snow, a brown dog is playing .\"\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "bleu_score = calculate_bleu_score(generated_translation, reference_translations)\n",
        "print(\"BLEU Score:\", bleu_score, \"for\",generated_translation)"
      ],
      "metadata": {
        "id": "5MWPdSDxKmIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ad1abb-c8e4-4e5d-8a3d-aebf865f0acd"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: BLEU = 27.97 53.8/41.7/27.3/10.0 (BP = 1.000 ratio = 1.444 hyp_len = 13 ref_len = 9) for  A brown dog playing in the snow with brown dog in the snow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to translate the pdf document\n",
        "\n",
        "import pdfplumber\n",
        "import textwrap\n",
        "from fpdf import FPDF\n",
        "\n",
        "def translate_pdf(input_file, translator_model,output_file):\n",
        "    translated_text = \"\"\n",
        "\n",
        "    with pdfplumber.open(input_file) as pdf:\n",
        "\n",
        "        for page in pdf.pages:\n",
        "            text_content = page.extract_text()\n",
        "            num_pages = len(pdf.pages)\n",
        "            a4_width_mm = 210\n",
        "            pt_to_mm = 0.35\n",
        "            fontsize_pt = 10\n",
        "            fontsize_mm = fontsize_pt * pt_to_mm\n",
        "            margin_bottom_mm = 10\n",
        "            character_width_mm = 7 * pt_to_mm\n",
        "            width_text = a4_width_mm / character_width_mm\n",
        "\n",
        "            pdf = FPDF(orientation='P', unit='mm', format='A4')\n",
        "            pdf.set_auto_page_break(True, margin=margin_bottom_mm)\n",
        "            pdf.add_page()\n",
        "            pdf.set_font(family='Courier', size=fontsize_pt)\n",
        "            sentences = text_content.split(\".\")\n",
        "\n",
        "            for sentence in sentences:\n",
        "                translated_sentence = translate(translator_model,sentence)\n",
        "                lines = textwrap.wrap(translated_sentence, width_text)\n",
        "\n",
        "                if len(lines) == 0:\n",
        "                    pdf.ln()\n",
        "\n",
        "                for wrap in lines:\n",
        "                    pdf.cell(0, fontsize_mm, wrap, ln=1)\n",
        "\n",
        "            pdf.output(output_file, 'F')"
      ],
      "metadata": {
        "id": "tJ3NBh0kKn9h"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the pdf file to translate\n",
        "\n",
        "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/input_de.pdf'"
      ],
      "metadata": {
        "id": "XMaZNggoKsYK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b9dcb8-594a-462e-e850-db81e4c04f05"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-18 11:47:32--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/input_de.pdf\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27628 (27K) [application/pdf]\n",
            "Saving to: ‘input_de.pdf.2’\n",
            "\n",
            "input_de.pdf.2      100%[===================>]  26.98K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-12-18 11:47:32 (765 KB/s) - ‘input_de.pdf.2’ saved [27628/27628]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the translated pdf file\n",
        "\n",
        "input_file_path = \"input_de.pdf\"\n",
        "output_file = 'output_en.pdf'\n",
        "translate_pdf(input_file_path, transformer,output_file)\n",
        "print(\"Translated PDF file is saved as:\", output_file)"
      ],
      "metadata": {
        "id": "jiuTXT24Kuyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce4d8f5-4042-4631-eeb9-a348f3585ac4"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated PDF file is saved as: output_en.pdf\n"
          ]
        }
      ]
    }
  ]
}