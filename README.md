# Transformer_Translation
- This project uses a Transformer Seq2Seq architecture for language translation.
- The Seq2Seq model has TokenEmbedding, PositionEncoding and multiple encoder and decoder layers embedded within the transformer.
- Separate encode and decode functions are created within the model, so encoder and decoder outputs can be visualized.
- Inputs and outputs and visualized along the project.
- A function is created to test the model translation and another function to calculate the bleu score.
- Finally a function is created to translate a pdf document from german to english.
